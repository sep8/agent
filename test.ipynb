{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from models.chat_model import ChatModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def member_func(args):\n",
    "    name = args.get('name')\n",
    "    members = {\n",
    "        \"James\": \"James is a member of A team\",\n",
    "        \"Jim\": \"Jim is a member of B team\",\n",
    "        \"Jimmy\": \"Jimmy is a member of C team\",\n",
    "        \"Jimothy\": \"Jimothy is a member D the team\",\n",
    "    }\n",
    "    return f\"{members[name]}\"\n",
    "\n",
    "\n",
    "member_tool = dotdict({\n",
    "    \"name\": \"Member\",\n",
    "    \"func\": member_func,\n",
    "    \"description\": \"useful for when you query someone belongs to which team\",\n",
    "    \"args\": {'name': {'title': 'Name', 'type': 'string'}}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools:\"\"\"\n",
    "FORMAT_INSTRUCTIONS = \"\"\"Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "```\n",
    "{{{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}}}\n",
    "```\n",
    "\n",
    "Follow this format:\n",
    "\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}}}\n",
    "```\"\"\"\n",
    "SUFFIX = \"\"\"Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
    "Thought:\"\"\"\n",
    "\n",
    "HUMAN_MESSAGE_TEMPLATE = \"{input}\\n\\n{agent_scratchpad}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate(object):\n",
    "    def __init__(self, input_variables, messages):\n",
    "        self.input_variables = input_variables\n",
    "        self.messages = messages\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        messages = []\n",
    "        for message in self.messages:\n",
    "            text = message['template'].format(**kwargs)\n",
    "            messages.append({\n",
    "                \"role\": message['role'],\n",
    "                \"content\": text\n",
    "            })\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, tools, stop=['Observation:'], max_iterations=15, **kwargs):\n",
    "        self.model = ChatModel()\n",
    "        self._stop = stop\n",
    "        self.name_to_tool_map = self._re_tools(tools)\n",
    "        self.prompt = self.create_prompt(tools)\n",
    "        self.max_iterations = max_iterations\n",
    "        self.observation_prefix = kwargs.get(\n",
    "            'observation_prefix', \"Observation: \")\n",
    "        self.llm_prefix = kwargs.get('llm_prefix', \"Thought:\")\n",
    "        self.verbose = kwargs.get('verbose', False)\n",
    "\n",
    "    def create_prompt(\n",
    "        self,\n",
    "        tools,\n",
    "        prefix: str = PREFIX,\n",
    "        suffix: str = SUFFIX,\n",
    "        human_message_template: str = HUMAN_MESSAGE_TEMPLATE,\n",
    "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
    "        input_variables=None\n",
    "    ):\n",
    "        tool_strings = []\n",
    "        for tool in tools:\n",
    "            args_schema = re.sub(\n",
    "                \"}\", \"}}}}\", re.sub(\"{\", \"{{{{\", str(tool.args)))\n",
    "            tool_strings.append(\n",
    "                f\"{tool.name}: {tool.description}, args: {args_schema}\")\n",
    "        formatted_tools = \"\\n\".join(tool_strings)\n",
    "        tool_names = \", \".join([tool.name for tool in tools])\n",
    "        format_instructions = format_instructions.format(tool_names=tool_names)\n",
    "        template = \"\\n\\n\".join(\n",
    "            [prefix, formatted_tools, format_instructions, suffix])\n",
    "        if input_variables is None:\n",
    "            input_variables = [\"input\", \"agent_scratchpad\"]\n",
    "\n",
    "        messages = [{\n",
    "            \"role\": \"system\",\n",
    "            \"template\": template,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"template\": human_message_template\n",
    "        }]\n",
    "\n",
    "        prompt = PromptTemplate(input_variables, messages)\n",
    "        return prompt\n",
    "\n",
    "    def _re_tools(self, tools):\n",
    "        name_to_tool_map = {}\n",
    "        for tool in tools:\n",
    "            name_to_tool_map[tool.name] = dotdict({\n",
    "                \"run\": tool.func\n",
    "            })\n",
    "        return name_to_tool_map\n",
    "\n",
    "    def _construct_scratchpad(self, intermediate_steps):\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\n{self.observation_prefix}{observation}\\n{self.llm_prefix}\"\n",
    "        if thoughts:\n",
    "            return (\n",
    "                f\"This was your previous work \"\n",
    "                f\"(but I haven't seen any of it! I only see what \"\n",
    "                f\"you return as final answer):\\n{thoughts}\"\n",
    "            )\n",
    "        else:\n",
    "            return thoughts\n",
    "\n",
    "    def run(self, **kwargs):\n",
    "        intermediate_steps = []\n",
    "        iterations = 0\n",
    "        while iterations <= self.max_iterations:\n",
    "            next_step_output = self._take_next_step(intermediate_steps, kwargs)\n",
    "            if (next_step_output.type == 'finished'):\n",
    "                return next_step_output.output\n",
    "\n",
    "            intermediate_steps.extend(next_step_output)\n",
    "            iterations += 1\n",
    "\n",
    "    def _output_parse(self, text):\n",
    "        try:\n",
    "            action_match = re.search(r\"```(.*?)```?\", text, re.DOTALL)\n",
    "            if action_match is not None:\n",
    "                response = json.loads(\n",
    "                    action_match.group(1).strip().replace('json\\n', '\\n'), strict=False)\n",
    "                if isinstance(response, list):\n",
    "                    # gpt turbo frequently ignores the directive to emit a single action\n",
    "                    response = response[0]\n",
    "                if response[\"action\"] == \"Final Answer\":\n",
    "                    return dotdict({\n",
    "                        \"type\": \"finished\",\n",
    "                        \"output\": response[\"action_input\"],\n",
    "                        \"text\": text\n",
    "                    })\n",
    "                else:\n",
    "                    return dotdict({\n",
    "                        \"type\": \"step\",\n",
    "                        \"tool\": response[\"action\"],\n",
    "                        \"tool_input\": response.get(\"action_input\", {}),\n",
    "                        \"log\": text\n",
    "                    })\n",
    "            else:\n",
    "                return dotdict({\n",
    "                    \"type\": \"finished\",\n",
    "                    \"output\": text,\n",
    "                    \"text\": text\n",
    "                })\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Could not parse LLM output: {text}\") from e\n",
    "\n",
    "    def get_full_inputs(self, intermediate_steps, **kwargs):\n",
    "        \"\"\"Create the full inputs for the llm from intermediate steps.\"\"\"\n",
    "        thoughts = self._construct_scratchpad(intermediate_steps)\n",
    "        new_inputs = {\"agent_scratchpad\": thoughts, \"stop\": self._stop}\n",
    "        full_inputs = {**kwargs, **new_inputs}\n",
    "        return full_inputs\n",
    "\n",
    "    def prep_prompts(self, input_list):\n",
    "        \"\"\"Prepare prompts from inputs.\"\"\"\n",
    "        stop = None\n",
    "        if \"stop\" in input_list[0]:\n",
    "            stop = input_list[0][\"stop\"]\n",
    "        prompts = []\n",
    "        for inputs in input_list:\n",
    "            selected_inputs = {k: inputs[k]\n",
    "                               for k in self.prompt.input_variables}\n",
    "            prompt = self.prompt.format(**selected_inputs)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        return prompts, stop\n",
    "\n",
    "    def _take_next_step(self, intermediate_steps, inputs):\n",
    "        full_inputs = self.get_full_inputs(intermediate_steps, **inputs)\n",
    "\n",
    "        prompts, stop = self.prep_prompts([full_inputs])\n",
    "\n",
    "        if self.verbose:\n",
    "            messages = [message['content'] for message in prompts[0]]\n",
    "            print(\"\\n\".join(messages))\n",
    "\n",
    "        response = self.model(messages=prompts[0], stop=stop)\n",
    "        output = self._output_parse(response)\n",
    "\n",
    "        if (output.type == 'finished'):\n",
    "            return output\n",
    "        actions = []\n",
    "        if (output.tool is not None):\n",
    "            actions = [output]\n",
    "        else:\n",
    "            actions = output\n",
    "        result = []\n",
    "        for action in actions:\n",
    "            if action.tool in self.name_to_tool_map:\n",
    "                tool = self.name_to_tool_map[action.tool]\n",
    "                observation = tool.run(action.tool_input)\n",
    "                result.append((action, observation))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'James belongs to which team?'\n",
    "tools = [member_tool]\n",
    "agent = Agent(tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "Member: useful for when you query someone belongs to which team, args: {{'name': {{'title': 'Name', 'type': 'string'}}}}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or Member\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}\n",
      "```\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
      "Thought:\n",
      "James belongs to which team?\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mrun(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "Cell \u001b[0;32mIn[7], line 74\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mwhile\u001b[39;00m iterations \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iterations:\n\u001b[1;32m     73\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_take_next_step(intermediate_steps, kwargs)\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mif\u001b[39;00m (next_step_output\u001b[39m.\u001b[39;49mtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfinished\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     75\u001b[0m         \u001b[39mreturn\u001b[39;00m next_step_output\u001b[39m.\u001b[39moutput\n\u001b[1;32m     77\u001b[0m     intermediate_steps\u001b[39m.\u001b[39mextend(next_step_output)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "output = agent.run(input=input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
