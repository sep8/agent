{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from models.chat_model import ChatModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def member_func(name: str):\n",
    "    members = {\n",
    "        \"James\": \"James is a member of A team\",\n",
    "        \"Jim\": \"Jim is a member of B team\",\n",
    "        \"Jimmy\": \"Jimmy is a member of C team\",\n",
    "        \"Jimothy\": \"Jimothy is a member D the team\",\n",
    "    }\n",
    "    return f\"{members[name]}\"\n",
    "\n",
    "\n",
    "member_tool = {\n",
    "    \"name\": \"Member\",\n",
    "    \"func\": member_func\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRUCTURED_TOOL_SYSTEM = 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nMember: useful for when you query someone belongs to which team, args: {{\\'name\\': {{\\'title\\': \\'Name\\', \\'type\\': \\'string\\'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Member\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:'\n",
    "\n",
    "USER_MESSAGE_TEMPLATE = \"{input}\\n\\n{agent_scratchpad}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages1 = [{'role': 'system', 'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nMember: useful for when you query someone belongs to which team, args: {{\\'name\\': {{\\'title\\': \\'Name\\', \\'type\\': \\'string\\'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Member\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:'}, {\n",
    "    'role': 'user', 'content': 'James belongs to which team?\\n\\n'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can use the Member tool to find out which team James belongs to. Let me do that for you.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Member\",\n",
      "  \"action_input\": {\n",
      "    \"name\": \"James\"\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "step1 = model(messages=messages1, stop=stop)\n",
    "print(step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate(object):\n",
    "    def __init__(self, input_variables, messages):\n",
    "        self.input_variables = input_variables\n",
    "        self.messages = messages\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        messages = []\n",
    "        for message in messages:\n",
    "            text = message['template'].format(**kwargs)\n",
    "            messages.append({\n",
    "                \"role\": message['role'],\n",
    "                \"content\": text\n",
    "            })\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, tools, stop=['Observation:'], max_iterations=15, **kwargs):\n",
    "        self.model = ChatModel()\n",
    "        self._stop = stop\n",
    "        self.name_to_tool_map = self._re_tools(tools)\n",
    "\n",
    "        messages = [{\n",
    "            \"role\": \"system\",\n",
    "            \"template\": STRUCTURED_TOOL_SYSTEM,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"template\": USER_MESSAGE_TEMPLATE,\n",
    "        }]\n",
    "        self.prompt = PromptTemplate(['input', 'agent_scratchpad'], messages)\n",
    "\n",
    "        self.system_prompt = STRUCTURED_TOOL_SYSTEM\n",
    "        self.user_prompt_template = USER_MESSAGE_TEMPLATE\n",
    "        self.max_iterations = max_iterations\n",
    "        self.observation_prefix = kwargs.get(\n",
    "            'observation_prefix', \"Observation: \")\n",
    "        self.llm_prefix = kwargs.get('llm_prefix', \"Thought:\")\n",
    "\n",
    "    def _re_tools(self, tools):\n",
    "        name_to_tool_map = {}\n",
    "        for tool in tools:\n",
    "            name_to_tool_map[tool[\"name\"]] = {\n",
    "                \"run\": tool[\"func\"]\n",
    "            }\n",
    "        return name_to_tool_map\n",
    "\n",
    "    def _construct_scratchpad(self, intermediate_steps):\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\n{self.observation_prefix}{observation}\\n{self.llm_prefix}\"\n",
    "        return (\n",
    "            f\"This was your previous work \"\n",
    "            f\"(but I haven't seen any of it! I only see what \"\n",
    "            f\"you return as final answer):\\n{thoughts}\"\n",
    "        )\n",
    "\n",
    "    def call(self, input):\n",
    "        intermediate_steps = []\n",
    "        iterations = 0\n",
    "        while iterations <= self.max_iterations:\n",
    "            next_step_output = self._take_next_setp(input, intermediate_steps)\n",
    "            if (next_step_output['type'] is 'finished'):\n",
    "                return next_step_output\n",
    "\n",
    "            intermediate_steps.extend(next_step_output)\n",
    "            iterations += 1\n",
    "\n",
    "    def _output_parse(self, text):\n",
    "        try:\n",
    "            action_match = re.search(r\"```(.*?)```?\", text, re.DOTALL)\n",
    "            if action_match is not None:\n",
    "                response = json.loads(\n",
    "                    action_match.group(1).strip(), strict=False)\n",
    "                if isinstance(response, list):\n",
    "                    # gpt turbo frequently ignores the directive to emit a single action\n",
    "                    response = response[0]\n",
    "                if response[\"action\"] == \"Final Answer\":\n",
    "                    return {\n",
    "                        \"type\": \"finished\",\n",
    "                        \"output\": response[\"action_input\"],\n",
    "                        \"text\": text\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"type\": \"step\",\n",
    "                        \"tool\": response[\"action\"],\n",
    "                        \"tool_input\": response.get(\"action_input\", {}),\n",
    "                        \"log\": text\n",
    "                    }\n",
    "            else:\n",
    "                return {\n",
    "                    \"type\": \"finished\",\n",
    "                    \"output\": text,\n",
    "                    \"text\": text\n",
    "                }\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Could not parse LLM output: {text}\") from e\n",
    "\n",
    "    def get_full_inputs(self, intermediate_steps, **kwargs):\n",
    "        \"\"\"Create the full inputs for the llm from intermediate steps.\"\"\"\n",
    "        thoughts = self._construct_scratchpad(intermediate_steps)\n",
    "        new_inputs = {\"agent_scratchpad\": thoughts, \"stop\": self._stop}\n",
    "        full_inputs = {**kwargs, **new_inputs}\n",
    "        return full_inputs\n",
    "\n",
    "    def prep_prompts(self, input_list):\n",
    "        \"\"\"Prepare prompts from inputs.\"\"\"\n",
    "        stop = None\n",
    "        if \"stop\" in input_list[0]:\n",
    "            stop = input_list[0][\"stop\"]\n",
    "        prompts = []\n",
    "        for inputs in input_list:\n",
    "            selected_inputs = {k: inputs[k] for k in self.prompt.input_variables}\n",
    "            prompt = self.prompt.format(**selected_inputs)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        return prompts, stop\n",
    "\n",
    "    def _take_next_setp(self, intermediate_steps, **kwargs):\n",
    "        full_inputs = self.get_full_inputs(intermediate_steps, **kwargs)\n",
    "\n",
    "        prompts, stop = self.prep_prompts([full_inputs])\n",
    "\n",
    "        response = self.model(messages=prompts, stop=stop)\n",
    "        output = self._output_parse(response)\n",
    "        \n",
    "        if (output['type'] is 'finished'):\n",
    "            return output\n",
    "        actions = []\n",
    "        if (output['tool'] is not None):\n",
    "            actions = [output]\n",
    "        else:\n",
    "            actions = output\n",
    "        result = []\n",
    "        for action in actions:\n",
    "            if action.tool in self.name_to_tool_map:\n",
    "                tool = self.name_to_tool_map[action.tool]\n",
    "                observation = tool['run'](action['tool_input'])\n",
    "                result.append((action, observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James belongs to team A.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"James belongs to team A.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages2 = [{'role': 'system', 'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nMember: useful for when you query someone belongs to which team, args: {{\\'name\\': {{\\'title\\': \\'Name\\', \\'type\\': \\'string\\'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Member\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:'}, {\n",
    "    'role': 'user', 'content': 'James belongs to which team?\\n\\nThis was your previous work (but I haven\\'t seen any of it! I only see what you return as final answer):\\nI can use the Member tool to find out which team James belongs to.\\nAction:\\n```\\n{\\n  \"action\": \"Member\",\\n  \"action_input\": {\\n    \"name\": \"James\"\\n  }\\n}\\n```\\nObservation: James is a member of A team\\nThought:'}]\n",
    "step2 = model(messages=messages2, stop=stop)\n",
    "print(step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James belongs to team A.\n",
      "Thought: This is the final answer to the question.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"James belongs to team A.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages3 = [{'role': 'user', 'content': 'Instructions:\\n--------------\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}}}\\n```\\n--------------\\nCompletion:\\n--------------\\nJames belongs to team A.\\nAction:\\n```json\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"James belongs to team A.\"\\n}\\n```\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\nOutputParserException(\\'Could not parse LLM output: James belongs to team A.\\\\nAction:\\\\n```json\\\\n{\\\\n  \"action\": \"Final Answer\",\\\\n  \"action_input\": \"James belongs to team A.\"\\\\n}\\\\n```\\')\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:'}]\n",
    "step3 = model(messages=messages3, stop=stop)\n",
    "print(step3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
