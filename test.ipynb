{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from models.chat_model import ChatModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcolors = {\n",
    "    'purple': '\\033[95m',\n",
    "    'blue': '\\033[94m',\n",
    "    'cyan' : '\\033[96m',\n",
    "    'green' :'\\033[92m',\n",
    "    'yellow' : '\\033[93m',\n",
    "    'red' : '\\033[91m',\n",
    "    'ENDC' : '\\033[0m',\n",
    "    'bold' : '\\033[1m',\n",
    "    'underline' : '\\033[4m'\n",
    " }\n",
    "    \n",
    "\n",
    "def pprint(message, color=None):\n",
    "    if color is None:\n",
    "        print(message)\n",
    "    else:\n",
    "        pcolor = bcolors[color] if color in bcolors else bcolors['ENDC']\n",
    "        print(f\"{pcolor}{message}{bcolors['ENDC']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools:\"\"\"\n",
    "FORMAT_INSTRUCTIONS = \"\"\"Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "```\n",
    "{{{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}}}\n",
    "```\n",
    "\n",
    "Follow this format:\n",
    "\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}}}\n",
    "```\"\"\"\n",
    "SUFFIX = \"\"\"Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
    "Thought:\"\"\"\n",
    "\n",
    "HUMAN_MESSAGE_TEMPLATE = \"{input}\\n\\n{agent_scratchpad}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate(object):\n",
    "    def __init__(self, input_variables, messages):\n",
    "        self.input_variables = input_variables\n",
    "        self.messages = messages\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        messages = []\n",
    "        for message in self.messages:\n",
    "            text = message['template'].format(**kwargs)\n",
    "            messages.append({\n",
    "                \"role\": message['role'],\n",
    "                \"content\": text\n",
    "            })\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.name = kwargs.get('name')\n",
    "        self.func = kwargs.get('func')\n",
    "        self.description = kwargs.get('description')\n",
    "        self.args = kwargs.get('args')\n",
    "\n",
    "    def run(self, args, verbose=False):\n",
    "        if verbose:\n",
    "            print(f\"Running {self.name} with args {args}\")\n",
    "        return self.func(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def member_func(args):\n",
    "    name = args.get('name')\n",
    "    members = {\n",
    "        \"James\": \"James is a member of A team\",\n",
    "        \"Jim\": \"Jim is a member of B team\",\n",
    "        \"Jimmy\": \"Jimmy is a member of C team\",\n",
    "        \"Jimothy\": \"Jimothy is a member D the team\",\n",
    "    }\n",
    "    return f\"{members[name]}\"\n",
    "\n",
    "\n",
    "member_tool = Tool(**{\n",
    "    \"name\": \"TeamQuery\",\n",
    "    \"func\": member_func,\n",
    "    \"description\": \"useful for when you want to know someone's team\",\n",
    "    \"args\": {'name': {'title': 'Name', 'type': 'string'}}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, tools, stop=['Observation:'], max_iterations=15, **kwargs):\n",
    "        self.model = ChatModel()\n",
    "        self._stop = stop\n",
    "        self.name_to_tool_map = self._re_tools(tools)\n",
    "        self.prompt = self.create_prompt(tools)\n",
    "        self.max_iterations = max_iterations\n",
    "        self.observation_prefix = kwargs.get(\n",
    "            'observation_prefix', \"Observation: \")\n",
    "        self.llm_prefix = kwargs.get('llm_prefix', \"Thought:\")\n",
    "        self.verbose = kwargs.get('verbose', False)\n",
    "        self.show_prompt = kwargs.get('show_prompt', False)\n",
    "\n",
    "    def create_prompt(\n",
    "        self,\n",
    "        tools,\n",
    "        prefix: str = PREFIX,\n",
    "        suffix: str = SUFFIX,\n",
    "        human_message_template: str = HUMAN_MESSAGE_TEMPLATE,\n",
    "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
    "        input_variables=None\n",
    "    ):\n",
    "        tool_strings = []\n",
    "        for tool in tools:\n",
    "            args_schema = re.sub(\n",
    "                \"}\", \"}}}}\", re.sub(\"{\", \"{{{{\", str(tool.args)))\n",
    "            tool_strings.append(\n",
    "                f\"{tool.name}: {tool.description}, args: {args_schema}\")\n",
    "        formatted_tools = \"\\n\".join(tool_strings)\n",
    "        tool_names = \", \".join([tool.name for tool in tools])\n",
    "        format_instructions = format_instructions.format(tool_names=tool_names)\n",
    "        template = \"\\n\\n\".join(\n",
    "            [prefix, formatted_tools, format_instructions, suffix])\n",
    "        if input_variables is None:\n",
    "            input_variables = [\"input\", \"agent_scratchpad\"]\n",
    "\n",
    "        messages = [{\n",
    "            \"role\": \"system\",\n",
    "            \"template\": template,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"template\": human_message_template\n",
    "        }]\n",
    "\n",
    "        prompt = PromptTemplate(input_variables, messages)\n",
    "        return prompt\n",
    "\n",
    "    def _re_tools(self, tools):\n",
    "        name_to_tool_map = {}\n",
    "        for tool in tools:\n",
    "            name_to_tool_map[tool.name] = tool\n",
    "        return name_to_tool_map\n",
    "\n",
    "    def _construct_scratchpad(self, intermediate_steps):\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\n{self.observation_prefix}{observation}\\n{self.llm_prefix}\"\n",
    "        if thoughts:\n",
    "            return (\n",
    "                f\"This was your previous work \"\n",
    "                f\"(but I haven't seen any of it! I only see what \"\n",
    "                f\"you return as final answer):\\n{thoughts}\"\n",
    "            )\n",
    "        else:\n",
    "            return thoughts\n",
    "\n",
    "    def _output_parse(self, text):\n",
    "        try:\n",
    "            action_match = re.search(r\"```(.*?)```?\", text, re.DOTALL)\n",
    "            if action_match is not None:\n",
    "                response = json.loads(\n",
    "                    action_match.group(1).strip().replace('json\\n', '\\n'), strict=False)\n",
    "                if isinstance(response, list):\n",
    "                    # gpt turbo frequently ignores the directive to emit a single action\n",
    "                    response = response[0]\n",
    "                return dotdict({\n",
    "                    \"type\": \"action\",\n",
    "                    \"tool\": response[\"action\"],\n",
    "                    \"tool_input\": response.get(\"action_input\", {}),\n",
    "                    \"state\" : 'finished' if response[\"action\"] == 'Final Answer' else 'intermediate',\n",
    "                    \"output\": response.get(\"action_input\", {}),\n",
    "                    \"log\": text\n",
    "                })\n",
    "            else:\n",
    "                return dotdict({\n",
    "                    \"type\": \"action\",\n",
    "                    \"state\": \"finished\",\n",
    "                    \"output\": text,\n",
    "                    \"log\": text\n",
    "                })\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Could not parse LLM output: {text}\") from e\n",
    "\n",
    "    def get_full_inputs(self, intermediate_steps, **kwargs):\n",
    "        \"\"\"Create the full inputs for the llm from intermediate steps.\"\"\"\n",
    "        thoughts = self._construct_scratchpad(intermediate_steps)\n",
    "        new_inputs = {\"agent_scratchpad\": thoughts, \"stop\": self._stop}\n",
    "        full_inputs = {**kwargs, **new_inputs}\n",
    "        return full_inputs\n",
    "\n",
    "    def prep_prompts(self, input_list):\n",
    "        \"\"\"Prepare prompts from inputs.\"\"\"\n",
    "        stop = None\n",
    "        if \"stop\" in input_list[0]:\n",
    "            stop = input_list[0][\"stop\"]\n",
    "        prompts = []\n",
    "        for inputs in input_list:\n",
    "            selected_inputs = {k: inputs[k]\n",
    "                               for k in self.prompt.input_variables}\n",
    "            prompt = self.prompt.format(**selected_inputs)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        return prompts, stop\n",
    "\n",
    "    def _track_steps_verbose(self, step_output):\n",
    "         if self.verbose:\n",
    "                if 'input' in step_output:\n",
    "                    pprint(f\"> Start: \\n{step_output['input']}\\n\", 'bold')   \n",
    "                else:\n",
    "                    action, observation = step_output\n",
    "                    though = action.log\n",
    "                    if not though.startswith(self.llm_prefix):\n",
    "                        though = f\"{self.llm_prefix}{though}\"\n",
    "                    pprint(f\"{though}\", 'green')\n",
    "                    pprint(f\"{self.observation_prefix}{observation}\\n\", 'blue')\n",
    "                    if action.tool == 'Final Answer':\n",
    "                        pprint(f\"> Finished: \\n{observation}\\n\", 'bold')\n",
    "\n",
    "    def run(self, **kwargs):\n",
    "        intermediate_steps = []\n",
    "        iterations = 0\n",
    "        self._track_steps_verbose(kwargs)\n",
    "        while iterations <= self.max_iterations:\n",
    "            next_step_outputs = self._take_next_step(intermediate_steps, kwargs)\n",
    "            next_step_output = next_step_outputs[0]\n",
    "            self._track_steps_verbose(next_step_output)\n",
    "            if (next_step_output[0].state == 'finished'):\n",
    "                return next_step_output[1]\n",
    "\n",
    "            intermediate_steps.extend(next_step_outputs)\n",
    "            iterations += 1\n",
    "\n",
    "    def _take_next_step(self, intermediate_steps, inputs):\n",
    "        full_inputs = self.get_full_inputs(intermediate_steps, **inputs)\n",
    "\n",
    "        prompts, stop = self.prep_prompts([full_inputs])\n",
    "\n",
    "        if self.show_prompt:\n",
    "            messages = [message['content'] for message in prompts[0]]\n",
    "            print(\"\\n\".join(messages))\n",
    "\n",
    "        response = self.model(messages=prompts[0], stop=stop)\n",
    "        output = self._output_parse(response)\n",
    "\n",
    "        if (output.state == 'finished'):\n",
    "            return [(output, output.output)]\n",
    "        actions = []\n",
    "        if (output.tool is not None):\n",
    "            actions = [output]\n",
    "        else:\n",
    "            actions = output\n",
    "        result = []\n",
    "        for action in actions:\n",
    "            if action.tool in self.name_to_tool_map:\n",
    "                tool = self.name_to_tool_map[action.tool]\n",
    "                observation = tool.run(action.tool_input)\n",
    "                result.append((action, observation))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'James belongs to which team?'\n",
    "tools = [member_tool]\n",
    "agent = Agent(tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m> Start: \n",
      "James belongs to which team?\n",
      "\u001b[0m\n",
      "\u001b[92mThought: I can use the TeamQuery tool to find out which team James belongs to.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"TeamQuery\",\n",
      "  \"action_input\": {\n",
      "    \"name\": \"James\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "\u001b[94mObservation: James is a member of A team\u001b[0m\n",
      "\u001b[92mThought:James belongs to team A.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"James belongs to team A.\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "\u001b[94mObservation: James belongs to team A.\u001b[0m\n",
      "\u001b[1m> Finished: \n",
      "James belongs to team A.\n",
      "\u001b[0m\n",
      "James belongs to team A.\n"
     ]
    }
   ],
   "source": [
    "agent.run(input=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
